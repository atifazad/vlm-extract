# VLM Extract Configuration
# Copy this file to .env and configure your preferred provider

# Primary Provider Selection
VLM_PROVIDER=ollama

# Global Configuration (applies to all providers)
VLM_TIMEOUT=30
VLM_MAX_RETRIES=3

# Provider-Specific Configuration
# You must configure the provider specified in VLM_PROVIDER

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5vl:7b
OLLAMA_API_KEY=

# OpenAI Configuration
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o
OPENAI_API_KEY=your_openai_api_key_here

# LocalAI Configuration
LOCALAI_BASE_URL=http://localhost:8080
LOCALAI_MODEL=llava
LOCALAI_API_KEY=

# File Processing Configuration
MAX_FILE_SIZE_MB=50

# PDF Processing Configuration
PDF_TEXT_EXTRACTION_ENABLED=true
PDF_MIN_TEXT_RATIO=0.1
PDF_FALLBACK_TO_VLM=true

# Batch Processing Configuration
BATCH_SIZE=5
BATCH_TIMEOUT=60 